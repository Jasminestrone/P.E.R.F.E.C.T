# P.R.E.S
Release: **Beta 3** | build: **2024.12.06**

## Features
- Hand tracking: Track and analyze hand movements to provide feedback on gestures.
- Eye tracking: Monitor eye movements to ensure you are maintaining good eye contact with your audience.
- Filler word detection: Identify and reduce the use of filler words like "um" and "uh" (coming soonâ„¢).

## Demo
Experience the full interactive demo [here](https://presnuvu.netlify.app/js-ai-body-tracker-master/index.html)! The demo showcases all current features of P.R.E.S in action, allowing you to see how it can enhance your presentations.

## Usage
P.R.E.S is designed to enhance your presentations by tracking body movements and hand gestures, as well as recognizing filler words. To use P.R.E.S, follow these steps:
1. Click "Start Presentation" to begin tracking
2. Enable camera and microphone when prompted
3. Use "Start Voice Input" to track speech patterns
4. Monitor your body language and volume in real-time

**Remember:** PRES is just a tool for assisting with your presenting, your slides should only be there to support your words, and you should **NEVER read off your slides**

### Examples of Use
- Use P.R.E.S during practice sessions to get feedback on your presentation skills.
- Review the feedback after your presentation to identify areas for improvement.


## Changelog
- Initial release with hand tracking, eye tracking, and basic functionality.
- Many many bug fixes

**Enjoy!**

-# GNU3 License | 2024 Jasmine, Gabe, Bradley

For more information and to contribute, visit our GitHub repository: [PRES](https://github.com/Jasminestrone/P.R.E.S)