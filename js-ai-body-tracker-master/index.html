<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <title>P.R.E.S</title>
    <!-- Bootstrap CSS -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css">
    <link rel="icon" type="image/x-icon" href="favicon.ico">
    <style>
        .flex-container {
            display: flex;
            flex-wrap: nowrap;
            justify-content: flex-start;
            align-items: flex-start;
        }

        .camera-section {
            margin-right: 20px;
        }

        .info-section {
            flex: 1;
        }
    </style>
</head>
<body>
    <div class="container">
        <h1 class="mt-4 text-center">P.R.E.S</h1>
        
        <div class="flex-container">
            <!-- Camera Output Section -->
            <div class="camera-section">
                <canvas id="canvas" width="640" height="480" style="border: 1px solid black;"></canvas>
            </div>

            <!-- Buttons and Text Section -->
            <div class="info-section">
                <!-- Voice Input Section -->
                <button id="startButton" class="btn btn-primary mt-3">Start Voice Input</button>
                <div id="output" class="mt-3"></div>

                <!-- Pitch Detection Section -->
                <div class="mt-4">
                    <h3>Pitch Detection</h3>
                    <button id="resume-button" class="btn btn-secondary">Resume Audio Context</button>
                    <div>
                        <strong>Pitch:</strong> <span id="pitch">-- Hz</span>
                    </div>
                    <div>
                        <strong>Clarity:</strong> <span id="clarity">-- %</span>
                    </div>
                </div>

                <!-- Eye Coordinates Output Section -->
                <div class="mt-4">
                    <h3>Eye Coordinates</h3>
                    <div>
                        <strong>Left Eye:</strong> <span id="leftEyeCoords">x: --, y: --, z: --</span>
                    </div>
                    <div>
                        <strong>Right Eye:</strong> <span id="rightEyeCoords">x: --, y: --, z: --</span>
                    </div>
                    <div>
                        <strong>Head Angle:</strong> <span id="headAngleInfo">Yaw: --, Pitch: --, Roll: --</span>
                    </div>
                </div>
            </div>
        </div>
    </div>

    <!-- TensorFlow.js and BlazePose -->
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-core"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-converter"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-backend-webgl"></script>
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/pose"></script>

    <!-- Pitch Detection -->
    <script type="module">
        import { PitchDetector } from "https://esm.sh/pitchy@4";

        document.addEventListener("DOMContentLoaded", () => {
            let audioContext, analyserNode, detector, input;

            document.getElementById("resume-button").addEventListener("click", () => {
                if (!audioContext) {
                    audioContext = new (window.AudioContext || window.webkitAudioContext)();
                    analyserNode = audioContext.createAnalyser();
                    detector = PitchDetector.forFloat32Array(analyserNode.fftSize);

                    navigator.mediaDevices.getUserMedia({ audio: true })
                        .then((stream) => {
                            const source = audioContext.createMediaStreamSource(stream);
                            source.connect(analyserNode);
                            input = new Float32Array(detector.inputLength);

                            function updatePitch() {
                                analyserNode.getFloatTimeDomainData(input);
                                const [pitch, clarity] = detector.findPitch(input, audioContext.sampleRate);

                                document.getElementById("pitch").textContent = pitch
                                    ? `${(Math.round(pitch * 10) / 10).toFixed(1)} Hz`
                                    : '-- Hz';
                                document.getElementById("clarity").textContent = clarity
                                    ? `${Math.round(clarity * 100)} %`
                                    : '-- %';
                                setTimeout(updatePitch, 100);
                            }
                            updatePitch();
                        })
                        .catch((error) => console.error("Audio stream error:", error));
                }
                audioContext.resume();
            });
        });
    </script>

    <!-- Voice Recognition -->
    <script>
        const startButton = document.getElementById('startButton');
        const outputDiv = document.getElementById('output');

        const recognition = new (window.SpeechRecognition || window.webkitSpeechRecognition)();
        recognition.lang = 'en-US';

        recognition.onstart = () => {
            startButton.textContent = 'Listening...';
        };

        recognition.onresult = (event) => {
            const transcript = event.results[0][0].transcript;
            outputDiv.textContent = `You said: ${transcript}`;
        };

        recognition.onend = () => {
            startButton.textContent = 'Start Voice Input';
        };

        startButton.addEventListener('click', () => {
            recognition.start();
        });
    </script>

    <!-- Body Tracking -->
    <script>
        async function initializeBlazePose() {
            const pose = new Pose({
                locateFile: (file) => `https://cdn.jsdelivr.net/npm/@mediapipe/pose/${file}`,
            });

            pose.setOptions({
                modelComplexity: 1,
                smoothLandmarks: true,
                enableSegmentation: false,
                minDetectionConfidence: 0.5,
                minTrackingConfidence: 0.5,
            });

            pose.onResults(onPoseResults);

            const video = await setupCamera();
            video.play();

            const canvas = document.getElementById('canvas');
            const ctx = canvas.getContext('2d');

            async function processVideo() {
                await pose.send({ image: video });
                requestAnimationFrame(processVideo);
            }

            processVideo();
        }

        async function setupCamera() {
            const video = document.createElement('video');
            video.width = 640;
            video.height = 480;
            video.style.display = 'none';
            document.body.appendChild(video);

            const stream = await navigator.mediaDevices.getUserMedia({
                video: { width: 640, height: 480 },
                audio: false,
            });

            video.srcObject = stream;
            await new Promise((resolve) => (video.onloadedmetadata = resolve));
            return video;
        }

        function onPoseResults(results) {
            const canvas = document.getElementById('canvas');
            const ctx = canvas.getContext('2d');
            ctx.clearRect(0, 0, canvas.width, canvas.height);

            ctx.drawImage(results.image, 0, 0, canvas.width, canvas.height);

            if (results.poseLandmarks) {
                const landmarks = results.poseLandmarks;

                // Extract key landmarks for waist, shoulders, and knees
            const leftShoulder = landmarks[6];
            const leftWaist = landmarks[12];
            const leftKnee = landmarks[14];

            // Calculate vector from waist to shoulder
            const waistToShoulderVector = {
                x: leftShoulder.x - leftWaist.x,
                y: leftShoulder.y - leftWaist.y,
                z: leftShoulder.z - leftWaist.z,
            };

            // Calculate vector from waist to knee
            const waistToKneeVector = {
                x: leftKnee.x - leftWaist.x,
                y: leftKnee.y - leftWaist.y,
                z: leftKnee.z - leftWaist.z,
            };

            // Function to calculate magnitude of a vector
            function magnitude(vector) {
                return Math.sqrt(vector.x ** 2 + vector.y ** 2 + vector.z ** 2);
            }

            // Function to calculate dot product of two vectors
            function dotProduct(vector1, vector2) {
                return vector1.x * vector2.x + vector1.y * vector2.y + vector1.z * vector2.z;
            }

            // Calculate the dot product of the two vectors
            const dot = dotProduct(waistToShoulderVector, waistToKneeVector);

            // Calculate the magnitudes of the vectors
            const magnitudeShoulder = magnitude(waistToShoulderVector);
            const magnitudeKnee = magnitude(waistToKneeVector);

            // Calculate the angle in radians
            const angleRadians = Math.acos(dot / (magnitudeShoulder * magnitudeKnee));

            // Convert to degrees if needed
            const angleDegrees = angleRadians * (180 / Math.PI);

            // Log the angle
            console.log('Angle at waist:', angleDegrees.toFixed(2));



                // Extract key landmarks for eye
                const leftEye = landmarks[2];
                const rightEye = landmarks[5];
                const nose = landmarks[0];

                // Calculate vectors for head orientation
                const eyeVector = {
                    x: rightEye.x - leftEye.x,
                    y: rightEye.y - leftEye.y,
                    z: rightEye.z - leftEye.z,
                };

                const noseVector = {
                    x: nose.x - (leftEye.x + rightEye.x) / 2,
                    y: nose.y - (leftEye.y + rightEye.y) / 2,
                    z: nose.z - (leftEye.z + rightEye.z) / 2,
                };

                // Calculate Yaw (rotation around vertical axis)
                const yaw = Math.atan2(eyeVector.z, eyeVector.x) * (180 / Math.PI);

                // Calculate Pitch (rotation around horizontal axis)
                const pitch = Math.atan2(noseVector.z, noseVector.y) * (180 / Math.PI);

                // Calculate Roll (tilt)
                const roll = Math.atan2(eyeVector.y, eyeVector.x) * (180 / Math.PI);

                // Normalize angles to 0–360 degrees
                const normalizeAngle = (angle) => (angle < 0 ? angle + 360 : angle);
                const yaw360 = normalizeAngle(yaw);
                const pitch360 = normalizeAngle(pitch);
                const roll360 = normalizeAngle(roll);

                // Log angles
                console.log(`Yaw: ${yaw360.toFixed(2)}°`);
                console.log(`Pitch: ${pitch360.toFixed(2)}°`);
                console.log(`Roll: ${roll360.toFixed(2)}°`);

                // Display coords and angles on the webpage
                document.getElementById('leftEyeCoords').textContent = `x: ${leftEye.x.toFixed(2)}, y: ${leftEye.y.toFixed(2)}, z: ${leftEye.z.toFixed(2)}`;
                document.getElementById('rightEyeCoords').textContent = `x: ${rightEye.x.toFixed(2)}, y: ${rightEye.y.toFixed(2)}, z: ${rightEye.z.toFixed(2)}`;
                document.getElementById('headAngleInfo').textContent = `Yaw: ${yaw360.toFixed(2)}°, Pitch: ${pitch360.toFixed(2)}°, Roll: ${roll360.toFixed(2)}°`;

                // Draw skeleton connections and keypoints
                const keypointConnections = [
                    // Face connections
                    [0, 1], [1, 2], [2, 3], // Left Eye connections
                    [0, 4], [4, 5], [5, 6], // Right Eye connections
                    [1, 7], [4, 8],         // Nose to ears
                    [9, 10],                // Mouth connections
                    // Body connections
                    [11, 12], [11, 13], [13, 15], [12, 14], [14, 16], // Legs
                    [11, 23], [12, 24], [23, 24], [23, 25], [24, 26]  // Upper body
                ];

                keypointConnections.forEach(([startIdx, endIdx]) => {
                    const start = landmarks[startIdx];
                    const end = landmarks[endIdx];

                    if (start.visibility > 0.5 && end.visibility > 0.5) {
                        ctx.beginPath();
                        ctx.moveTo(start.x * canvas.width, start.y * canvas.height);
                        ctx.lineTo(end.x * canvas.width, end.y * canvas.height);
                        ctx.strokeStyle = "blue";
                        ctx.lineWidth = 2;
                        ctx.stroke();
                    }
                });

                landmarks.forEach((landmark, index) => {
                    ctx.beginPath();
                    ctx.arc(landmark.x * canvas.width, landmark.y * canvas.height, 5, 0, 2 * Math.PI);

                    if (index === 2 || index === 5) {
                        ctx.fillStyle = "yellow"; // Eyes
                    } else {
                        ctx.fillStyle = "red"; // Other keypoints
                    }

                    ctx.fill();
                });
            }
        }



        document.addEventListener("DOMContentLoaded", () => {
            initializeBlazePose();
        });
    </script>
</body>
</html>
